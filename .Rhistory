CompanyAssocRules <- read.csv("Company.csv", head = TRUE)
#sort the data with specific attributes
AR_CompanyAssocRules <- CompanyAssocRules[,names(CompanyAssocRules) %in% c('Attrition','BusinessTravel','Department',
'EducationField','Gender','JobRole','MaritalStatus')]
# write as a output file
write.csv(AR_CompanyAssocRules, file="AR_CompanyAssocRules.csv", row.names = F, na = " ")
#install.packages("arules")
library(arules)
set.seed(9999)
ar_CompanyAssocRules <- read.transactions("AR_CompanyAssocRules.csv", sep =",", rm.duplicates = TRUE)
#summary of CompanyAssocRules data
summary(ar_CompanyAssocRules)
#display first five row
inspect(ar_CompanyAssocRules[1:5])
#build model bu using apriori function
apriori(ar_CompanyAssocRules)
AR_rules <- apriori(ar_CompanyAssocRules,parameter=list(support =0.01, confidence = 0.8,
minlen = 2), appearance=list(rhs=c("No", "Yes"), default="lhs"))
summary(AR_rules)
## keep tCompanyAssocRulesee decimal places
quality(AR_rules) <- round(quality(AR_rules), digits=4)
#Rules after sorting
SortingRules <- (sort(AR_rules, by = "lift"))
## find redundant rules
subset.matrix <- is.subset(SortingRules, SortingRules, sparse = FALSE)
subset.matrix[lower.tri(subset.matrix, diag = T)] <- NA
redundant <- colSums(subset.matrix, na.rm = T) >= 1
## which rules are redundant
which(redundant)
## remove redundant rules
PruningRules <- SortingRules[!redundant]
#PruningRules
inspect(PruningRules[1:5])
#Total of rules with Attrition 'Yes' and 'No'
subset(PruningRules, items %in% "Yes")
subset(PruningRules, items %in% "No")
#sort the data with specific attributes
AR_hr <- hr[,names(hr) %in% c('Attrition','BusinessTravel','Department',
'EducationField','Gender','JobRole','MaritalStatus')]
#sort the data with specific attributes
AR_Company <- Company[,names(Company) %in% c('Attrition','BusinessTravel','Department',
'EducationField','Gender','JobRole','MaritalStatus')]
#rerun again
Company <- read.csv("Company.csv", head = TRUE)
#sort the data with specific attributes
AR_Company <- Company[,names(Company) %in% c('Attrition','BusinessTravel','Department',
'EducationField','Gender','JobRole','MaritalStatus')]
# write as a output file
write.csv(AR_Company, file="AR_Company.csv", row.names = F, na = " ")
#install.packages("arules")
library(arules)
set.seed(3653)
ar_Company <- read.transactions("AR_Company.csv", sep =",", rm.duplicates = TRUE)
#summary of Company data
summary(ar_Company)
#display first five row
inspect(ar_Company[1:5])
#build model bu using apriori function
apriori(ar_Company)
set.seed(3653)
ar_CompanyAssocRules <- read.transactions("AR_CompanyAssocRules.csv", sep =",", rm.duplicates = TRUE)
#summary of CompanyAssocRules data
summary(ar_CompanyAssocRules)
#display first five row
inspect(ar_CompanyAssocRules[1:5])
#build model bu using apriori function
apriori(ar_CompanyAssocRules)
AR_rules <- apriori(ar_CompanyAssocRules,parameter=list(support =0.01, confidence = 0.8,
minlen = 2), appearance=list(rhs=c("No", "Yes"), default="lhs"))
summary(AR_rules)
## keep tCompanyAssocRulesee decimal places
quality(AR_rules) <- round(quality(AR_rules), digits=4)
#Rules after sorting
SortingRules <- (sort(AR_rules, by = "lift"))
## find redundant rules
subset.matrix <- is.subset(SortingRules, SortingRules, sparse = FALSE)
subset.matrix[lower.tri(subset.matrix, diag = T)] <- NA
redundant <- colSums(subset.matrix, na.rm = T) >= 1
## which rules are redundant
which(redundant)
## remove redundant rules
PruningRules <- SortingRules[!redundant]
#PruningRules
inspect(PruningRules[1:5])
#Total of rules with Attrition 'Yes' and 'No'
subset(PruningRules, items %in% "Yes")
subset(PruningRules, items %in% "No")
3653
3653
set.seed(3653)
#rerun again
Company <- read.csv("Company.csv", head = TRUE)
#sort the data with specific attributes
AR_Company <- Company[,names(Company) %in% c('Attrition','BusinessTravel','Department',
'EducationField','Gender','JobRole','MaritalStatus')]
# write as a output file
write.csv(AR_Company, file="AR_Company.csv", row.names = F, na = " ")
#install.packages("arules")
library(arules)
set.seed(3653)
ar_Company <- read.transactions("AR_Company.csv", sep =",", rm.duplicates = TRUE)
#summary of Company data
summary(ar_Company)
#display first five row
inspect(ar_Company[1:5])
#build model bu using apriori function
apriori(ar_Company)
AR_rules <- apriori(ar_Company,parameter=list(support =0.01, confidence = 0.8,
minlen = 2), appearance=list(rhs=c("No", "Yes"), default="lhs"))
summary(AR_rules)
## keep tCompanyee decimal places
quality(AR_rules) <- round(quality(AR_rules), digits=4)
#Rules after sorting
sortRules <- (sort(AR_rules, by = "lift"))
## find redundant rules
subset.matrix <- is.subset(sortRules, sortRules, sparse = FALSE)
subset.matrix[lower.tri(subset.matrix, diag = T)] <- NA
redundant <- colSums(subset.matrix, na.rm = T) >= 1
## which rules are redundant
which(redundant)
## remove redundant rules
pruneRules <- sortRules[!redundant]
#pruneRules
inspect(pruneRules[1:5])
#Total of rules with Attrition 'Yes' and 'No'
subset(pruneRules, items %in% "Yes")
subset(pruneRules, items %in% "No")
#install.packages("arulesViz")
#install.packages("viridisLite")
library(arulesViz)
#Read file
kNN <- read.csv(file="Company.csv",head=TRUE,sep = ",", stringsAsFactors = FALSE)
kNN
kNN$EmployeeCount <-NULL
kNN$StandardHours <-NULL
kNN$BusinessTravel <-NULL
kNN$EducationField <-NULL
kNN$Gender <-NULL
kNN$JobRole <-NULL
kNN$MaritalStatus <-NULL
kNN$Over18 <-NULL
kNN$OverTime <-NULL
kNN$Department <-NULL
str(kNN)
#randomize
set.seed(214805)
kNN_rand = kNN[order(runif(1470)),]
str(kNN_rand)
kNN_rand$Attrition
kNN$Attrition <- na.omit(kNN_rand$Attrition)
table(kNN_rand$Attrition)
factor(kNN_rand$Attrition, levels = c("No", "Yes"),labels = c("N", "Y"))
prop.table(table(kNN_rand$Attrition))
summary(kNN_rand)
normalize <- function(x) { return((x - min(x)) / (max(x)-min(x)))}
normalize(c(1,2,3,4,5))
normalize(c(10,20,30,40,50))
kNN_n <- as.data.frame(lapply(kNN_rand[3:25], normalize))
summary(kNN_n)
kNN_train <- kNN_n[1:1176, ]
kNN_test <- kNN_n[1177:1470, ]
kNN_train_labels <- kNN_rand[1:1176, 1]
kNN_test_labels <- kNN_rand[1177:1470, 1]
#install.packages("class")
library(class)
sqrt(1176)
kNN_test_pred <- knn(train = kNN_train, test = kNN_test, cl = kNN_train_labels, k=19)
install.packages("gmodels")
#install.packages("gmodels")
library("gmodels")
CrossTable(x = kNN_test_labels, y = kNN_test_pred,prop.chisq=FALSE)
#Load Library
library("e1071")
library("caret")
library("gmodels")
#read csv file
CompanyNaiveBaye <- read.csv("Company.csv")
#column names
colnames(CompanyNaiveBaye)
# clean data.
summary(CompanyNaiveBaye)
str(CompanyNaiveBaye)
any(is.na(CompanyNaiveBaye))
#remove unwanted columns.
head(CompanyN)
CompanyN <- CompanyNaiveBaye[ , -(c(3,6,9,10,18,20,24,26,28,31,32,34,35,36))]
#change 1st column name to Age
colnames(CompanyN)[1] <- "Age"
#write a new csv
write.csv(CompanyN, file="employeeD_new.csv", row.names = F, na = " ")
# check column names
colnames(CompanyN)
# read new csv file second time running code.
CompanyN<- read.csv("employeeD_new.csv")
#split data one for train and other for test
set.seed(2)
#takes all observation, randomly select 80% of employees and 20%, so two value.
#80% of time I want to select 1 and 20% time 2.
p <- sample(2, nrow(CompanyN), prob = c(0.8,0.2), replace =T)
train<- CompanyN[p==1,]
test<- CompanyN[p==2,]
nrow(train)
nrow(test)
#compare yes and no in two dataset
prop.table(table(train$Attrition))
prop.table(table(test$Attrition))
#naive bayes
emp <- naiveBayes(Attrition ~ Age + DailyRate + Department + Education + Education + EnvironmentSatisfaction + Gender + HourlyRate + JobInvolvement + JobLevel + JobSatisfaction + MonthlyIncome + NumCompaniesWorked + OverTime + PerformanceRating + YearsInCurrentRole, data = train)
prop.table(table(CompanyN$Attrition))
#naive bayes
emp <- naiveBayes(Attrition ~ Age + DailyRate + Department + Education + Education + EnvironmentSatisfaction + Gender + HourlyRate + JobInvolvement + JobLevel + JobSatisfaction + MonthlyIncome + NumCompaniesWorked + OverTime + PerformanceRating + YearsInCurrentRole, data = train)
emp
prediction2<- predict(emp, test)
confusionMatrix(table(prediction2,test$Attrition))
#install.packages("party")
library(party)
library(rpart.plot)
library(rpart)
# reading the Company.csv data set
CompanyDT = read.csv("Company.csv", header = TRUE)
# lets look at it structure of the dataset from IBM
str(CompanyDT)
normalize <- function(x) { return((x - min(x)) / (max(x)-min(x)))}
normalize(c(1,2,3,4,5))
normalize(c(10,20,30,40,50))
barplot(prop.table(table(CompanyDT$Attrition)),
col = rainbow(2),
ylim = c(0, 0.7),
main = "Class Distribution")
# randomize first
set.seed(6969) # sync the randomization / allows reproducibility
# create a training and a test sub-set
pd <- sample(2, nrow(CompanyDT),replace = TRUE, prob = c(0.8,0.2))
train <- CompanyDT[pd==1,]
test <-CompanyDT[pd==2,]
# data for Developing predictive Model
table(train$Attrition)
prop.table(table(train$Attrition))
# reading the Company.csv data set
CompanyDT = read.csv("Company.csv", header = TRUE)
# lets look at it structure of the dataset from IBM
str(CompanyDT)
normalize <- function(x) { return((x - min(x)) / (max(x)-min(x)))}
normalize(c(1,2,3,4,5))
normalize(c(1,2,3,4,5))
normalize(c(10,20,30,40,50))
barplot(prop.table(table(CompanyDT$Attrition)),
col = rainbow(2),
ylim = c(0, 0.7),
main = "Class Distribution")
# randomize first
set.seed(6969) # sync the randomization / allows reproducibility
# create a training and a test sub-set
pd <- sample(2, nrow(CompanyDT),replace = TRUE, prob = c(0.8,0.2))
train <- CompanyDT[pd==1,]
test <-CompanyDT[pd==2,]
prop.table(table(train$Attrition))
table(train$Attrition)
table(test$Attrition)
# data for Developing predictive Model
table(train$Attrition)
# check their distributions
prop.table(table(train$Attrition))
prop.table(table(test$Attrition))
#original
prop.table(table(CompanyDT$Attrition))
# install and load the C5.0 library
#install.packages("C50")
library(C50)
# train the model
CompanyDT_model = C5.0(train[,-c(2,22)], train$Attrition)
summary(CompanyDT_model)
plot(CompanyDT_model)
m2 = rpart(Attrition ~ ., data=CompanyDT[,-c(22)], method="class")
m2
# Decision with rpart
m2 <- rpart(Attrition~DailyRate+DistanceFromHome+JobInvolvement+MonthlyRate+RelationshipSatisfaction+WorkLifeBalance
+ TrainingTimesLastYear+RelationshipSatisfaction +EnvironmentSatisfaction+HourlyRate, CompanyDT)
library(rpart.plot)
rpart.plot(m2,extra = 4)
# test the model
CompanyDT_pred = predict(CompanyDT_model, test)
CompanyDT_pred
#install.packages("gmodels")
library("gmodels")
# CrossTable with all details
CrossTable(test$Attrition, CompanyDT_pred)
# CrossTable that is a lot clearer
CrossTable(test$Attrition, CompanyDT_pred, prop.chisq = FALSE, prop.c
= FALSE, prop.r = FALSE, dnn =c('actual_Attrition', 'predicted_Attrition'))
#Run CSV File
CompanyAssocRules <- read.csv("Company.csv", head = TRUE)
#Run CSV File
CompanyAssocRules <- read.csv("Company.csv", head = TRUE)
#sort the data with specific attributes
AR_CompanyAssocRules <- CompanyAssocRules[,names(CompanyAssocRules) %in% c('Attrition','BusinessTravel','Department',
'EducationField','Gender','JobRole','MaritalStatus')]
# write as a output file
write.csv(AR_CompanyAssocRules, file="AR_CompanyAssocRules.csv", row.names = F, na = " ")
#install.packages("arules")
library(arules)
set.seed(3653)
ar_CompanyAssocRules <- read.transactions("AR_CompanyAssocRules.csv", sep =",", rm.duplicates = TRUE)
#summary of CompanyAssocRules data
summary(ar_CompanyAssocRules)
#display first five row
inspect(ar_CompanyAssocRules[1:5])
#build model bu using apriori function
apriori(ar_CompanyAssocRules)
AR_rules <- apriori(ar_CompanyAssocRules,parameter=list(support =0.01, confidence = 0.8,
minlen = 2), appearance=list(rhs=c("No", "Yes"), default="lhs"))
summary(AR_rules)
## keep tCompanyAssocRulesee decimal places
quality(AR_rules) <- round(quality(AR_rules), digits=4)
#Rules after sorting
SortingRules <- (sort(AR_rules, by = "lift"))
## find redundant rules
subset.matrix <- is.subset(SortingRules, SortingRules, sparse = FALSE)
subset.matrix[lower.tri(subset.matrix, diag = T)] <- NA
redundant <- colSums(subset.matrix, na.rm = T) >= 1
## which rules are redundant
which(redundant)
## remove redundant rules
PruningRules <- SortingRules[!redundant]
#PruningRules
inspect(PruningRules[1:5])
#Total of rules with Attrition 'Yes' and 'No'
subset(PruningRules, items %in% "Yes")
subset(PruningRules, items %in% "No")
#install.packages("arulesViz")
#install.packages("viridisLite")
library(arulesViz)
library(viridisLite)
plot(SortingRules)
plot(PruningRules)
plot((PruningRules[1:5]), method = "graph", control = list(type="items"))
plot(PruningRules[1:20], method = "paracoord", control = list(reorder = TRUE))
plot(PruningRules, method = "grouped")
#Load Library
library("e1071")
library("caret")
library("gmodels")
#read csv file
CompanyNaiveBaye <- read.csv("Company.csv")
#column names
colnames(CompanyNaiveBaye)
# clean data.
summary(CompanyNaiveBaye)
str(CompanyNaiveBaye)
any(is.na(CompanyNaiveBaye))
#remove unwanted columns.
head(CompanyN)
CompanyN <- CompanyNaiveBaye[ , -(c(3,6,9,10,18,20,24,26,28,31,32,34,35,36))]
#change 1st column name to Age
colnames(CompanyN)[1] <- "Age"
#write a new csv
write.csv(CompanyN, file="employeeD_new.csv", row.names = F, na = " ")
# check column names
colnames(CompanyN)
# read new csv file second time running code.
CompanyN<- read.csv("employeeD_new.csv")
#remove unwanted columns.
head(CompanyN)
CompanyN <- CompanyNaiveBaye[ , -(c(3,6,9,10,18,20,24,26,28,31,32,34,35,36))]
#change 1st column name to Age
colnames(CompanyN)[1] <- "Age"
#write a new csv
write.csv(CompanyN, file="employeeD_new.csv", row.names = F, na = " ")
# check column names
colnames(CompanyN)
# read new csv file second time running code.
CompanyN<- read.csv("employeeD_new.csv")
#split data one for train and other for test
set.seed(2)
#takes all observation, randomly select 80% of employees and 20%, so two value.
#80% of time I want to select 1 and 20% time 2.
p <- sample(2, nrow(CompanyN), prob = c(0.8,0.2), replace =T)
train<- CompanyN[p==1,]
test<- CompanyN[p==2,]
nrow(train)
nrow(test)
#compare yes and no in two dataset
prop.table(table(train$Attrition))
prop.table(table(test$Attrition))
#Original File Attrition
prop.table(table(CompanyN$Attrition))
#naive bayes
emp <- naiveBayes(Attrition ~ Age + DailyRate + Department + Education + Education + EnvironmentSatisfaction + Gender + HourlyRate + JobInvolvement + JobLevel + JobSatisfaction + MonthlyIncome + NumCompaniesWorked + OverTime + PerformanceRating + YearsInCurrentRole, data = train)
emp
prediction2<- predict(emp, test)
confusionMatrix(table(prediction2,test$Attrition))
prediction2<- predict(emp, test)
confusionMatrix(table(prediction2,test$Attrition))
#put tarin data in cross tables
CrossTable(prediction2,test$Attrition, prop.chisq = FALSE,prop.t = FALSE, dnn = c('predicted', 'actual'))
prediction3<- predict(emp, train)
confusionMatrix(table(prediction3,train$Attrition))
#put test data in crosstable
CrossTable(prediction3,train$Attrition, prop.chisq = FALSE,prop.t = FALSE, dnn = c('predicted', 'actual'))
#probability
prediction2<- predict(emp, test, type="raw")
prediction2
#put tarin data in cross tables
CrossTable(prediction2,test$Attrition, prop.chisq = FALSE,prop.t = FALSE, dnn = c('predicted', 'actual'))
prediction2<- predict(emp, test)
confusionMatrix(table(prediction2,test$Attrition))
prediction3<- predict(emp, train)
confusionMatrix(table(prediction3,train$Attrition))
#put test data in crosstable
CrossTable(prediction3,train$Attrition, prop.chisq = FALSE,prop.t = FALSE, dnn = c('predicted', 'actual'))
#install.packages("party")
library(party)
library(rpart.plot)
# reading the Company.csv data set
CompanyDT = read.csv("Company.csv", header = TRUE)
library(rpart)
# lets look at it structure of the dataset from IBM
str(CompanyDT)
normalize <- function(x) { return((x - min(x)) / (max(x)-min(x)))}
normalize(c(1,2,3,4,5))
normalize(c(10,20,30,40,50))
barplot(prop.table(table(CompanyDT$Attrition)),
col = rainbow(2),
ylim = c(0, 0.7),
main = "Class Distribution")
# randomize first
set.seed(6969) # sync the randomization / allows reproducibility
# create a training and a test sub-set
pd <- sample(2, nrow(CompanyDT),replace = TRUE, prob = c(0.8,0.2))
train <- CompanyDT[pd==1,]
test <-CompanyDT[pd==2,]
# data for Developing predictive Model
table(train$Attrition)
prop.table(table(train$Attrition))
table(train$Attrition)
table(test$Attrition)
# check their distributions
prop.table(table(train$Attrition))
prop.table(table(test$Attrition))
#original
prop.table(table(CompanyDT$Attrition))
# install and load the C5.0 library
#install.packages("C50")
library(C50)
# train the model
CompanyDT_model = C5.0(train[,-c(2,22)], train$Attrition)
summary(CompanyDT_model)
plot(CompanyDT_model)
m2 = rpart(Attrition ~ ., data=CompanyDT[,-c(22)], method="class")
m2
# Decision with rpart
m2 <- rpart(Attrition~DailyRate+DistanceFromHome+JobInvolvement+MonthlyRate+RelationshipSatisfaction+WorkLifeBalance
+ TrainingTimesLastYear+RelationshipSatisfaction +EnvironmentSatisfaction+HourlyRate, CompanyDT)
library(rpart.plot)
rpart.plot(m2,extra = 4)
# test the model
CompanyDT_pred = predict(CompanyDT_model, test)
CompanyDT_pred
#install.packages("gmodels")
library("gmodels")
# CrossTable with all details
CrossTable(test$Attrition, CompanyDT_pred)
# CrossTable that is a lot clearer
CrossTable(test$Attrition, CompanyDT_pred, prop.chisq = FALSE, prop.c
= FALSE, prop.r = FALSE, dnn =c('actual_Attrition', 'predicted_Attrition'))
#Run CSV File
CompanyAssocRules <- read.csv("Company.csv", head = TRUE)
#sort the data with specific attributes
AR_CompanyAssocRules <- CompanyAssocRules[,names(CompanyAssocRules) %in% c('Attrition','BusinessTravel','Department',
'EducationField','Gender','JobRole','MaritalStatus')]
# write as a output file
write.csv(AR_CompanyAssocRules, file="AR_CompanyAssocRules.csv", row.names = F, na = " ")
#install.packages("arules")
library(arules)
set.seed(3653)
ar_CompanyAssocRules <- read.transactions("AR_CompanyAssocRules.csv", sep =",", rm.duplicates = TRUE)
#summary of CompanyAssocRules data
summary(ar_CompanyAssocRules)
#display first five row
inspect(ar_CompanyAssocRules[1:5])
#build model bu using apriori function
apriori(ar_CompanyAssocRules)
AR_rules <- apriori(ar_CompanyAssocRules,parameter=list(support =0.01, confidence = 0.8,
minlen = 2), appearance=list(rhs=c("No", "Yes"), default="lhs"))
summary(AR_rules)
## keep tCompanyAssocRulesee decimal places
quality(AR_rules) <- round(quality(AR_rules), digits=4)
#Rules after sorting
SortingRules <- (sort(AR_rules, by = "lift"))
## find redundant rules
subset.matrix <- is.subset(SortingRules, SortingRules, sparse = FALSE)
subset.matrix[lower.tri(subset.matrix, diag = T)] <- NA
redundant <- colSums(subset.matrix, na.rm = T) >= 1
## which rules are redundant
which(redundant)
## remove redundant rules
PruningRules <- SortingRules[!redundant]
#PruningRules
inspect(PruningRules[1:5])
#Total of rules with Attrition 'Yes' and 'No'
subset(PruningRules, items %in% "Yes")
subset(PruningRules, items %in% "No")
###Visualize plot diagram###
#install.packages("arulesViz")
#install.packages("viridisLite")
library(arulesViz)
library(viridisLite)
plot(SortingRules)
plot(PruningRules)
plot((PruningRules[1:5]), method = "graph", control = list(type="items"))
plot(PruningRules[1:20], method = "paracoord", control = list(reorder = TRUE))
plot(PruningRules, method = "grouped")
